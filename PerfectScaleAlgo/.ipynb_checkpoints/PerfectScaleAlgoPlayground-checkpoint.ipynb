{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd   \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import random\n",
    "import concurrent\n",
    "from packaging import version\n",
    "\n",
    "if version.parse(pd.__version__) < version.parse(\"1.2.0\"):\n",
    "    print(\"Pandas 1.2 required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_data_src = pd.read_csv(\"DEV_10_dec - pods.csv\")\n",
    "\n",
    "pods_data_src['req_cpu_milli_core'] = pd.to_numeric(pods_data_src['req_cpu_milli_core'])\n",
    "\n",
    "pods_data_src['req_mem_mb'] = pd.to_numeric(pods_data_src['req_mem_byte']) / 1000000\n",
    "\n",
    "#set zero values to a low value\n",
    "pods_data_src.loc[pods_data_src.req_mem_mb == 0, 'req_mem_mb'] = 0.001\n",
    "pods_data_src.loc[pods_data_src.req_cpu_milli_core == 0, 'req_cpu_milli_core'] = 1\n",
    "\n",
    "pods_data_src.owner_name.fillna(pods_data_src.pod_name, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#regex to clean out any text after the number\n",
    "def clean_data(value):\n",
    "    return (re.sub(r'^([0-9]+).*', '\\\\1', value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_data_src = pd.read_csv(\"instances.csv\")\n",
    "\n",
    "nodes_data_src.vCPUs = nodes_data_src.vCPUs.apply(clean_data)\n",
    "\n",
    "nodes_data_src['cpu']  = pd.to_numeric(nodes_data_src.vCPUs, errors='coerce')*1000\n",
    "\n",
    "nodes_data_src['memory'] = pd.to_numeric(nodes_data_src.Memory, errors='coerce')*1000\n",
    "\n",
    "nodes_data_src['cost'] =  pd.to_numeric(nodes_data_src['Linux Reserved cost'], errors='coerce')\n",
    "\n",
    "nodes_data_src = nodes_data_src[['API Name','Name','cpu', 'memory', 'cost']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data model\n",
    "#\n",
    "def create_data_model(cpu, memory, pods):\n",
    "    \"\"\"Create the data for the example.\"\"\"\n",
    "    data = {}    \n",
    "    data['req_cpu'] = pods['req_cpu_milli_core'].tolist()\n",
    "    data['req_memory'] = pods['req_mem_mb'].tolist()\n",
    "    data['items'] = list(range(len( pods)))\n",
    "    data['bins'] = data['items']\n",
    "    data['cpu_capacity'] = cpu\n",
    "    data['memory_capacity'] = memory\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_solver(data):\n",
    "    x = {}\n",
    "    y = {}\n",
    "    # Create the mip solver with the SCIP backend.\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    #solver.SetNumThreads(6)\n",
    "    \n",
    "   # solver.SetTimeLimit(30000)\n",
    "\n",
    "    # Variables\n",
    "    # x[i, j] = 1 if item i is packed in bin j.\n",
    "\n",
    "    for i in data['items']:\n",
    "        for j in data['bins']:\n",
    "            x[(i, j)] = solver.IntVar(0, 1, 'x_%i_%i' % (i, j))\n",
    "\n",
    "    # y[j] = 1 if bin j is used.\n",
    "\n",
    "    for j in data['bins']:\n",
    "        y[j] = solver.IntVar(0, 1, 'y[%i]' % j)\n",
    "    \n",
    "  \n",
    "    # Constraints\n",
    "    # Each item must be in exactly one bin.\n",
    "    for i in data['items']:\n",
    "        solver.Add(sum(x[i, j] for j in data['bins']) == 1)\n",
    "\n",
    "\n",
    "    # The amount packed in each bin cannot exceed its capacity.\n",
    "    for j in data['bins']:\n",
    "        solver.Add(\n",
    "            sum(x[(i, j)] * data['req_cpu'][i] for i in data['items']) <= y[j] * data['cpu_capacity'])\n",
    "\n",
    "\n",
    "    for j in data['bins']:\n",
    "        solver.Add(\n",
    "            sum(x[(i, j)] * data['req_memory'][i] for i in data['items']) <= y[j] * data['memory_capacity'])\n",
    "    \n",
    "    \n",
    "    return solver, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solve(solver, data, x, y, pods):\n",
    "    solver.Minimize(solver.Sum([y[j] for j in data['bins']]))\n",
    "    status = solver.Solve()\n",
    "    solution = pd.DataFrame(columns = pods.columns, index = pods.index).sort_index().truncate(-1, -1 ).reindex()\n",
    "    solution['node_name'] = \"\" #TODO - fix the dataframe definition to include all columns\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        num_bins = 0.\n",
    "        for j in data['bins']:\n",
    "            if y[j].solution_value() == 1:\n",
    "                bin_items = []\n",
    "                bin_pods = pd.DataFrame(columns = pods.columns, index = pods.index).sort_index().truncate(-1, -1 ).reindex()\n",
    "                bin_cpu = 0\n",
    "                bin_memory = 0\n",
    "                for i in data['items']:\n",
    "                    if x[i, j].solution_value() > 0:\n",
    "                        bin_items.append(i)\n",
    "                       # print(pods.iloc[[i]])\n",
    "                        bin_pods = bin_pods.append(pods.iloc[[i]])\n",
    "                        bin_pods['node_name'] = 'node' + str(j)\n",
    "                        bin_cpu += data['req_cpu'][i]\n",
    "                        bin_memory += data['req_memory'][i]\n",
    "                if bin_cpu > 0 or bin_memory>0:\n",
    "                    solution = solution.append(bin_pods.copy())\n",
    "                    num_bins += 1\n",
    "\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.')\n",
    "        \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution(node_group, curr_node, pods_data):\n",
    "    global solutions\n",
    "    #print (f\"{datetime.now().strftime('%D %H:%M:%S')}: Solving for {curr_node['API Name']} (cpu: {curr_node.cpu}, memory: {curr_node.memory})\")\n",
    "    \n",
    "    #pod_placement = pd.DataFrame(['node_name', 'node_type', 'node_cpu', 'node_memory'] + [pods_data.columns])\n",
    "    \n",
    "    if (len(solutions[(solutions.cpu == curr_node.cpu) & (solutions.memory == curr_node.memory)]) == 0):\n",
    "        \n",
    "        data = create_data_model(curr_node.cpu, curr_node.memory, pods_data)\n",
    "        solver,x,y = create_solver(data)\n",
    "        pod_placement = solve(solver, data, x, y, pods_data)    \n",
    "        if len(pod_placement) > 0:\n",
    "            i = 5\n",
    "           # print (f\"{datetime.now().strftime('%D %H:%M:%S')}: Solution for {curr_node['API Name']}: {len(pod_placement.node_name.unique())} nodes, cost: {len(pod_placement) * curr_node.cost}\")\n",
    "        else:\n",
    "            i= 6\n",
    "           # print (f\"{datetime.now().strftime('%D %H:%M:%S')}: No solution found for {curr_node['API Name']}\")\n",
    "    else:\n",
    "        old_node = solutions[(solutions.cpu == curr_node.cpu) & (solutions.memory == curr_node.memory)].iloc[0]\n",
    "        pod_placement = old_node.pod_placement.copy()        \n",
    "        #print (f\"{datetime.now().strftime('%D %H:%M:%S')}: Reusing solution for {old_node['name']}\")\n",
    "            \n",
    "    pod_placement['node_type'] = curr_node['API Name']\n",
    "    pod_placement['node_cpu'] = curr_node.cpu\n",
    "    pod_placement['node_memory'] = curr_node.memory\n",
    "    pod_placement['node_group'] = node_group\n",
    "    \n",
    "    #solutions = solutions.append({'name': curr_node['API Name'], 'cpu': curr_node['cpu'], 'memory': curr_node['memory'], \n",
    "    #                 'num_nodes': len(solution), 'cost': curr_cost, \n",
    "    #                 'solution': solution}, ignore_index = True)\n",
    "    \n",
    "    #if curr_cost < min_cost:\n",
    "    #    best_node = nodes_data.iloc[i]\n",
    "    #    min_cost = curr_cost\n",
    "    #    best_solution = solution\n",
    "    \n",
    "    #print(solutions.columns)\n",
    "        \n",
    "    return pd.DataFrame(\n",
    "        np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n",
    "                len(pod_placement.node_name.unique()), curr_node.cost * len(pod_placement.node_name.unique()), pod_placement]).reshape(1,7),\n",
    "        columns = solutions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "all_solutions = pd.DataFrame(columns = [\"node_group\", \"name\", \"cpu\", \"memory\", \"num_nodes\", \"cost\", \"pod_placement\"])\n",
    "\n",
    "for node_group in pods_data_src.node_group.unique():\n",
    "    \n",
    "    print(f\"Starting nodegroup {node_group}... {datetime.now().strftime('%D %H:%M:%S')}\")\n",
    "\n",
    "    pods_data = pods_data_src[(pods_data_src.node_group == node_group) &  \n",
    "                              (pods_data_src.owner_kind != 'DaemonSet') & \n",
    "                              (pods_data_src.req_cpu_milli_core>0) &\n",
    "                              (pods_data_src.req_mem_byte>0) ][['namespace', 'owner_name', 'req_mem_mb', 'req_cpu_milli_core' ]]\n",
    "\n",
    "    daemonset = pods_data_src[(pods_data_src.node_group == node_group) & (pods_data_src.owner_kind == 'DaemonSet')].\\\n",
    "                groupby([ \"owner_name\", \"namespace\"]).agg({'req_cpu_milli_core':'mean', 'req_mem_mb':'mean'})\n",
    "    \n",
    "    overhead = {'cpu': daemonset.req_cpu_milli_core.sum(), 'memory': daemonset.req_mem_mb.sum()}\n",
    "    \n",
    "    nodes_data = nodes_data_src[(nodes_data_src.cpu >= pods_data.req_cpu_milli_core.max()) & \n",
    "                                (nodes_data_src.memory >= pods_data.req_mem_mb.max()) ]\n",
    "\n",
    "    nodes_data.cpu = nodes_data.cpu - overhead['cpu']\n",
    "    nodes_data.memory = nodes_data.memory - overhead['memory']\n",
    "\n",
    "    print(f\"Nodegroup {node_group}. Detected {len(nodes_data)} suitable nodes out of {total_node_types} total\")\n",
    "\n",
    "    pods = pods_data\n",
    "\n",
    "    nodes_data = nodes_data\n",
    "    \n",
    "    solutions = pd.DataFrame(columns = all_solutions.columns)\n",
    "\n",
    "    for i in range(1, len(nodes_data)):\n",
    "        curr_node = nodes_data.iloc[i]    \n",
    "        solution = get_solution(node_group, curr_node, pods)\n",
    "        solutions = solutions.append(solution, ignore_index = True)\n",
    "\n",
    "        \n",
    "    #Add daemonsets \n",
    "    for i in range(0, len(solutions) -1):\n",
    "        all_nodes = solutions.iloc[i].pod_placement.groupby(['node_group', 'node_name', 'node_type', 'node_cpu', 'node_memory']).size().\\\n",
    "                reset_index().iloc[:,0:5]  \n",
    "\n",
    "        daemonset_placement = all_nodes.merge(daemonset.reset_index(), how='cross', left_on=None, right_on=None)\n",
    "\n",
    "        solutions.iloc[i].pod_placement  = solutions.iloc[i].pod_placement.append(daemonset_placement)\n",
    "\n",
    "    solutions.node_group = node_group\n",
    "    \n",
    "    all_solutions = all_solutions.append(solutions.copy())\n",
    "    \n",
    "    \n",
    "print(\"All solutions found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions[solutions.columns[:-1]]\n",
    "len(solutions)\n",
    "#display(solutions[[\"name\", \"cpu\", \"memory\", \"num_nodes\", \"cost\"]].sort_values(by = \"cost\",\n",
    "#                    ascending = \"False\").reset_index(drop = True))\n",
    "\n",
    "solutions[[\"node_group\", \"name\", \"cpu\", \"memory\", \"num_nodes\", \"cost\"]].sort_values(by = \"cost\",\n",
    "                    ascending = \"False\").reset_index(drop = True).to_csv(\"solutions.csv\", index=False, )\n",
    "\n",
    "\n",
    "solutions = solutions[solutions.cost > 0].sort_values(by = \"cost\", axis=0,\n",
    "                    ascending = \"False\").reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution: \n",
      "\n",
      "Node: r5ad.xlarge, cpu: 3588,          memory: 31408.603136, hourly cost: 0.165, number of nodes: 1\n"
     ]
    }
   ],
   "source": [
    "best_solution = solutions.iloc[0]\n",
    "\n",
    "print(f\"Best solution: \\n\")    \n",
    "print(f\"Node: {best_solution['name']}, cpu: {best_solution.cpu},\\\n",
    "          memory: {best_solution.memory}, hourly cost: {best_solution.cost}, number of nodes: {len(best_solution.pod_placement.node_name.unique())}\")\n",
    "\n",
    "\n",
    "#display(best_solution.pod_placement)\n",
    "\n",
    "best_solution.pod_placement.to_csv('best_solution.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_placements = solutions.iloc[0].pod_placement.copy()\n",
    "\n",
    "for i in range(1, len(all_solutions)):\n",
    "    all_placements = all_placements.append( all_solutions.pod_placement.iloc[i].copy())\n",
    "    \n",
    "all_placements.to_csv(\"all_solutions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 5, 0, 2, 9, 7, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_placements.node_group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats\n",
    "#20 nodes - 1 hour with 6 threads\n",
    "#20 nodes - 1 hour with 3 threads\n",
    "#20 nodes - 1 hour with 12 threads\n",
    "\n",
    "\n",
    "#Number of Pods\n",
    "#200 pods  7 sec\n",
    "#400 pods - 64 sec\n",
    "#600 pods - 9 mins\n",
    "#800 pods - 36 mins\n",
    "#1000\n",
    "\n",
    "#2000 pods - stopped after 18 hours?\n",
    "\n",
    "\n",
    "#on parallelism https://github.com/google/or-tools/issues/1656"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
