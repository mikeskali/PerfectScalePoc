{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd   \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import random\n",
    "import concurrent\n",
    "from packaging import version\n",
    "\n",
    "if version.parse(pd.__version__) < version.parse(\"1.2.0\"):\n",
    "    print(\"Pandas 1.2 required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_data_src = pd.read_csv(\"DEV_10_dec - pods.csv\")\n",
    "\n",
    "pods_data_src['req_cpu_milli_core'] = pd.to_numeric(pods_data_src['req_cpu_milli_core'])\n",
    "\n",
    "pods_data_src['req_mem_mb'] = pd.to_numeric(pods_data_src['req_mem_byte']) / 1000000\n",
    "\n",
    "#set zero values to a low value\n",
    "pods_data_src.loc[pods_data_src.req_mem_mb == 0, 'req_mem_mb'] = 0.001\n",
    "pods_data_src.loc[pods_data_src.req_cpu_milli_core == 0, 'req_cpu_milli_core'] = 1\n",
    "\n",
    "pods_data_src.owner_name.fillna(pods_data_src.pod_name, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#regex to clean out any text after the number\n",
    "def clean_data(value):\n",
    "    return (re.sub(r'^([0-9]+).*', '\\\\1', value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_data_src = pd.read_csv(\"instances.csv\")\n",
    "\n",
    "nodes_data_src.vCPUs = nodes_data_src.vCPUs.apply(clean_data)\n",
    "\n",
    "nodes_data_src['cpu']  = pd.to_numeric(nodes_data_src.vCPUs, errors='coerce')*1000\n",
    "\n",
    "nodes_data_src['memory'] = pd.to_numeric(nodes_data_src.Memory, errors='coerce')*1000\n",
    "\n",
    "nodes_data_src['cost'] =  pd.to_numeric(nodes_data_src['Linux Reserved cost'], errors='coerce')\n",
    "\n",
    "nodes_data_src = nodes_data_src[nodes_data_src['cost']>0][['API Name','Name','cpu', 'memory', 'cost']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data model\n",
    "#\n",
    "def create_data_model(cpu, memory, pods):\n",
    "    \"\"\"Create the data for the example.\"\"\"\n",
    "    data = {}    \n",
    "    data['req_cpu'] = pods['req_cpu_milli_core'].tolist()\n",
    "    data['req_memory'] = pods['req_mem_mb'].tolist()\n",
    "    data['items'] = list(range(len( pods)))\n",
    "    data['bins'] = data['items']\n",
    "    data['cpu_capacity'] = cpu\n",
    "    data['memory_capacity'] = memory\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_solver(data):\n",
    "    x = {}\n",
    "    y = {}\n",
    "    # Create the mip solver with the SCIP backend.\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    #solver.SetNumThreads(6)\n",
    "    \n",
    "   # solver.SetTimeLimit(30000)\n",
    "\n",
    "    # Variables\n",
    "    # x[i, j] = 1 if item i is packed in bin j.\n",
    "\n",
    "    for i in data['items']:\n",
    "        for j in data['bins']:\n",
    "            x[(i, j)] = solver.IntVar(0, 1, 'x_%i_%i' % (i, j))\n",
    "\n",
    "    # y[j] = 1 if bin j is used.\n",
    "\n",
    "    for j in data['bins']:\n",
    "        y[j] = solver.IntVar(0, 1, 'y[%i]' % j)\n",
    "    \n",
    "  \n",
    "    # Constraints\n",
    "    # Each item must be in exactly one bin.\n",
    "    for i in data['items']:\n",
    "        solver.Add(sum(x[i, j] for j in data['bins']) == 1)\n",
    "\n",
    "\n",
    "    # The amount packed in each bin cannot exceed its capacity.\n",
    "    for j in data['bins']:\n",
    "        solver.Add(\n",
    "            sum(x[(i, j)] * data['req_cpu'][i] for i in data['items']) <= y[j] * data['cpu_capacity'])\n",
    "\n",
    "\n",
    "    for j in data['bins']:\n",
    "        solver.Add(\n",
    "            sum(x[(i, j)] * data['req_memory'][i] for i in data['items']) <= y[j] * data['memory_capacity'])\n",
    "    \n",
    "    \n",
    "    return solver, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solve(solver, data, x, y, pods):\n",
    "    solver.Minimize(solver.Sum([y[j] for j in data['bins']]))\n",
    "    status = solver.Solve()\n",
    "    solution = pd.DataFrame(columns = pods.columns, index = pods.index).sort_index().truncate(-1, -1 ).reindex()\n",
    "    solution['node_name'] = \"\" #TODO - fix the dataframe definition to include all columns\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        num_bins = 0.\n",
    "        for j in data['bins']:\n",
    "            if y[j].solution_value() == 1:\n",
    "                bin_items = []\n",
    "                bin_pods = pd.DataFrame(columns = pods.columns, index = pods.index).sort_index().truncate(-1, -1 ).reindex()\n",
    "                bin_cpu = 0\n",
    "                bin_memory = 0\n",
    "                for i in data['items']:\n",
    "                    if x[i, j].solution_value() > 0:\n",
    "                        bin_items.append(i)\n",
    "                       # print(pods.iloc[[i]])\n",
    "                        bin_pods = bin_pods.append(pods.iloc[[i]])\n",
    "                        bin_pods['node_name'] = 'node' + str(j)\n",
    "                        bin_cpu += data['req_cpu'][i]\n",
    "                        bin_memory += data['req_memory'][i]\n",
    "                if bin_cpu > 0 or bin_memory>0:\n",
    "                    solution = solution.append(bin_pods.copy())\n",
    "                    num_bins += 1\n",
    "\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.')\n",
    "        \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution(node_group, curr_node, pods_data):\n",
    "    global solutions\n",
    "    #print (f\"{datetime.now().strftime('%D %H:%M:%S')}: Solving for {curr_node['API Name']} (cpu: {curr_node.cpu}, memory: {curr_node.memory})\")\n",
    "    \n",
    "    #pod_placement = pd.DataFrame(['node_name', 'node_type', 'node_cpu', 'node_memory'] + [pods_data.columns])\n",
    "    \n",
    "    if (len(solutions[(solutions.cpu == curr_node.cpu) & (solutions.memory == curr_node.memory)]) == 0):\n",
    "        \n",
    "        data = create_data_model(curr_node.cpu, curr_node.memory, pods_data)\n",
    "        solver,x,y = create_solver(data)\n",
    "        pod_placement = solve(solver, data, x, y, pods_data)    \n",
    "        if len(pod_placement) > 0:\n",
    "            i = 5\n",
    "           # print (f\"{datetime.now().strftime('%D %H:%M:%S')}: Solution for {curr_node['API Name']}: {len(pod_placement.node_name.unique())} nodes, cost: {len(pod_placement) * curr_node.cost}\")\n",
    "        else:\n",
    "            i= 6\n",
    "           # print (f\"{datetime.now().strftime('%D %H:%M:%S')}: No solution found for {curr_node['API Name']}\")\n",
    "    else:\n",
    "        old_node = solutions[(solutions.cpu == curr_node.cpu) & (solutions.memory == curr_node.memory)].iloc[0]\n",
    "        pod_placement = old_node.pod_placement.copy()        \n",
    "        #print (f\"{datetime.now().strftime('%D %H:%M:%S')}: Reusing solution for {old_node['name']}\")\n",
    "            \n",
    "    pod_placement['node_type'] = curr_node['API Name']\n",
    "    pod_placement['node_cpu'] = curr_node.cpu\n",
    "    pod_placement['node_memory'] = curr_node.memory\n",
    "    pod_placement['node_group'] = node_group\n",
    "    \n",
    "    #solutions = solutions.append({'name': curr_node['API Name'], 'cpu': curr_node['cpu'], 'memory': curr_node['memory'], \n",
    "    #                 'num_nodes': len(solution), 'cost': curr_cost, \n",
    "    #                 'solution': solution}, ignore_index = True)\n",
    "    \n",
    "    #if curr_cost < min_cost:\n",
    "    #    best_node = nodes_data.iloc[i]\n",
    "    #    min_cost = curr_cost\n",
    "    #    best_solution = solution\n",
    "    \n",
    "    #print(solutions.columns)\n",
    "        \n",
    "    return pd.DataFrame(\n",
    "        np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n",
    "                len(pod_placement.node_name.unique()), curr_node.cost * len(pod_placement.node_name.unique()), pod_placement]).reshape(1,7),\n",
    "        columns = solutions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nodegroup 3... 01/25/21 00:10:45\n",
      "Nodegroup 3. Detected 297 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem does not have an optimal solution.\n",
      "Starting nodegroup 4... 01/25/21 00:13:38\n",
      "Nodegroup 4. Detected 360 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nodegroup 5... 01/25/21 00:13:44\n",
      "Nodegroup 5. Detected 332 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem does not have an optimal solution.\n",
      "Starting nodegroup 0... 01/25/21 00:16:25\n",
      "Nodegroup 0. Detected 333 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem does not have an optimal solution.\n",
      "Starting nodegroup 2... 01/25/21 00:16:32\n",
      "Nodegroup 2. Detected 360 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nodegroup 9... 01/25/21 00:16:39\n",
      "Nodegroup 9. Detected 333 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem does not have an optimal solution.\n",
      "Starting nodegroup 7... 01/25/21 00:16:45\n",
      "Nodegroup 7. Detected 333 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nodegroup 6... 01/25/21 00:16:51\n",
      "Nodegroup 6. Detected 283 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem does not have an optimal solution.\n",
      "The problem does not have an optimal solution.\n",
      "Starting nodegroup 8... 01/25/21 00:16:56\n",
      "Nodegroup 8. Detected 333 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem does not have an optimal solution.\n",
      "Starting nodegroup 1... 01/25/21 00:17:01\n",
      "Nodegroup 1. Detected 360 suitable nodes out of 369 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander zaidelson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:5489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-22-8dc0b47996aa>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array([node_group, curr_node['API Name'], curr_node['cpu'], curr_node['memory'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All solutions found\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "all_solutions = pd.DataFrame(columns = [\"node_group\", \"name\", \"cpu\", \"memory\", \"num_nodes\", \"cost\", \"pod_placement\"])\n",
    "\n",
    "for node_group in pods_data_src.node_group.unique():\n",
    "    \n",
    "    print(f\"Starting nodegroup {node_group}... {datetime.now().strftime('%D %H:%M:%S')}\")\n",
    "\n",
    "    pods_data = pods_data_src[(pods_data_src.node_group == node_group) &  \n",
    "                              (pods_data_src.owner_kind != 'DaemonSet') & \n",
    "                              (pods_data_src.req_cpu_milli_core>0) &\n",
    "                              (pods_data_src.req_mem_byte>0) ][['namespace', 'owner_name', 'req_mem_mb', 'req_cpu_milli_core' ]]\n",
    "\n",
    "    daemonset = pods_data_src[(pods_data_src.node_group == node_group) & (pods_data_src.owner_kind == 'DaemonSet')].\\\n",
    "                groupby([ \"owner_name\", \"namespace\"]).agg({'req_cpu_milli_core':'mean', 'req_mem_mb':'mean'})\n",
    "    \n",
    "    overhead = {'cpu': daemonset.req_cpu_milli_core.sum(), 'memory': daemonset.req_mem_mb.sum()}\n",
    "    \n",
    "    nodes_data = nodes_data_src[(nodes_data_src.cpu >= pods_data.req_cpu_milli_core.max()) & \n",
    "                                (nodes_data_src.memory >= pods_data.req_mem_mb.max()) ]\n",
    "\n",
    "    nodes_data.cpu = nodes_data.cpu - overhead['cpu']\n",
    "    nodes_data.memory = nodes_data.memory - overhead['memory']\n",
    "\n",
    "    print(f\"Nodegroup {node_group}. Detected {len(nodes_data)} suitable nodes out of {len(nodes_data_src)} total\")\n",
    "\n",
    "    pods = pods_data\n",
    "\n",
    "    nodes_data = nodes_data\n",
    "    \n",
    "    solutions = pd.DataFrame(columns = all_solutions.columns)\n",
    "\n",
    "    for i in range(1, len(nodes_data)):\n",
    "        curr_node = nodes_data.iloc[i]    \n",
    "        solution = get_solution(node_group, curr_node, pods)\n",
    "        solutions = solutions.append(solution, ignore_index = True)\n",
    "\n",
    "        \n",
    "    #Add daemonsets \n",
    "    for i in range(0, len(solutions) -1):\n",
    "        all_nodes = solutions.iloc[i].pod_placement.groupby(['node_group', 'node_name', 'node_type', 'node_cpu', 'node_memory']).size().\\\n",
    "                reset_index().iloc[:,0:5]  \n",
    "\n",
    "        daemonset_placement = all_nodes.merge(daemonset.reset_index(), how='cross', left_on=None, right_on=None)\n",
    "\n",
    "        solutions.iloc[i].pod_placement  = solutions.iloc[i].pod_placement.append(daemonset_placement)\n",
    "\n",
    "    solutions.node_group = node_group\n",
    "    \n",
    "    all_solutions = all_solutions.append(solutions.copy())\n",
    "    \n",
    "    \n",
    "print(\"All solutions found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions[solutions.columns[:-1]]\n",
    "len(solutions)\n",
    "#display(solutions[[\"name\", \"cpu\", \"memory\", \"num_nodes\", \"cost\"]].sort_values(by = \"cost\",\n",
    "#                    ascending = \"False\").reset_index(drop = True))\n",
    "\n",
    "solutions[[\"node_group\", \"name\", \"cpu\", \"memory\", \"num_nodes\", \"cost\"]].sort_values(by = \"cost\",\n",
    "                    ascending = \"False\").reset_index(drop = True).to_csv(\"solutions.csv\", index=False, )\n",
    "\n",
    "\n",
    "solutions = solutions[solutions.cost > 0].sort_values(by = \"cost\", axis=0,\n",
    "                    ascending = \"False\").reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution: \n",
      "\n",
      "Node: m5a.2xlarge, cpu: 7587,          memory: 31408.601136, hourly cost: 0.217, number of nodes: 1\n"
     ]
    }
   ],
   "source": [
    "best_solution = solutions.iloc[0]\n",
    "\n",
    "print(f\"Best solution: \\n\")    \n",
    "print(f\"Node: {best_solution['name']}, cpu: {best_solution.cpu},\\\n",
    "          memory: {best_solution.memory}, hourly cost: {best_solution.cost}, number of nodes: {len(best_solution.pod_placement.node_name.unique())}\")\n",
    "\n",
    "\n",
    "#display(best_solution.pod_placement)\n",
    "\n",
    "best_solution.pod_placement.to_csv('best_solution.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_placements = solutions.iloc[0].pod_placement.copy()\n",
    "\n",
    "for i in range(1, len(all_solutions)):\n",
    "    all_placements = all_placements.append( all_solutions.pod_placement.iloc[i].copy())\n",
    "    \n",
    "all_placements.to_csv(\"all_solutions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 5, 0, 2, 9, 7, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_placements.node_group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats\n",
    "#20 nodes - 1 hour with 6 threads\n",
    "#20 nodes - 1 hour with 3 threads\n",
    "#20 nodes - 1 hour with 12 threads\n",
    "\n",
    "\n",
    "#Number of Pods\n",
    "#200 pods  7 sec\n",
    "#400 pods - 64 sec\n",
    "#600 pods - 9 mins\n",
    "#800 pods - 36 mins\n",
    "#1000\n",
    "\n",
    "#2000 pods - stopped after 18 hours?\n",
    "\n",
    "\n",
    "#on parallelism https://github.com/google/or-tools/issues/1656"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
